{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a synthetic multivariate time series dataset of at least 1 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psutilNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached psutil-6.1.0-cp37-abi3-win_amd64.whl.metadata (23 kB)\n",
      "Using cached psutil-6.1.0-cp37-abi3-win_amd64.whl (254 kB)\n",
      "Installing collected packages: psutil\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 6.1.0\n",
      "    Uninstalling psutil-6.1.0:\n",
      "      Successfully uninstalled psutil-6.1.0\n",
      "Successfully installed psutil-6.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\sarth\\anaconda3\\Lib\\site-packages\\~sutil'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "pip install --force-reinstall psutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import time\n",
    "import wmi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "output_file = \"synthetic_dataset.csv\" \n",
    "sampling_rate_hz = 1  \n",
    "duration_minutes = 300 \n",
    "wmi_interface = wmi.WMI()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_metrics():\n",
    "    # Timestamp\n",
    "    timestamp = datetime.datetime.now()\n",
    "\n",
    "    # CPU temperature\n",
    "    try:\n",
    "        temp = wmi_interface.MSAcpi_ThermalZoneTemperature()[0].CurrentTemperature / 10.0 - 273.15\n",
    "    except:\n",
    "        temp = None \n",
    "\n",
    "    # CPU usage percentage\n",
    "    cpu_usage = psutil.cpu_percent(interval=None)\n",
    "\n",
    "    # CPU load\n",
    "    cpu_load = os.getloadavg()[0] if hasattr(os, \"getloadavg\") else None\n",
    "\n",
    "    # Memory usage\n",
    "    memory = psutil.virtual_memory().percent\n",
    "\n",
    "    # Battery level\n",
    "    battery = psutil.sensors_battery().percent if psutil.sensors_battery() else None\n",
    "\n",
    "    # Disk usage\n",
    "    try:\n",
    "        disk_usage = psutil.disk_usage(\"C:\\\\\").percent  \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching disk usage: {e}\")\n",
    "        disk_usage = None\n",
    "\n",
    "    # Network stats\n",
    "    net_io = psutil.net_io_counters()\n",
    "    bytes_sent = net_io.bytes_sent\n",
    "    bytes_recv = net_io.bytes_recv\n",
    "\n",
    "    return [timestamp, temp, cpu_usage, cpu_load, memory, battery, disk_usage, bytes_sent, bytes_recv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\n",
    "    \"timestamp\",\n",
    "    \"cpu_temperature\",\n",
    "    \"cpu_usage\",\n",
    "    \"cpu_load\",\n",
    "    \"memory_usage\",\n",
    "    \"battery_level\",\n",
    "    \"disk_usage\",\n",
    "    \"bytes_sent\",\n",
    "    \"bytes_recv\",\n",
    "]\n",
    "\n",
    "# Create and write the header to the CSV file\n",
    "with open(output_file, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collection started... (Press Ctrl+C to stop)\n",
      "Elapsed time: 1 min, Current dataset size: 0.00 MB\n",
      "Elapsed time: 2 min, Current dataset size: 0.00 MB\n",
      "Elapsed time: 3 min, Current dataset size: 0.01 MB\n",
      "Elapsed time: 4 min, Current dataset size: 0.01 MB\n",
      "Elapsed time: 5 min, Current dataset size: 0.02 MB\n",
      "Elapsed time: 6 min, Current dataset size: 0.02 MB\n",
      "Elapsed time: 7 min, Current dataset size: 0.02 MB\n",
      "Elapsed time: 8 min, Current dataset size: 0.02 MB\n",
      "Elapsed time: 9 min, Current dataset size: 0.03 MB\n",
      "Elapsed time: 10 min, Current dataset size: 0.03 MB\n",
      "Elapsed time: 11 min, Current dataset size: 0.04 MB\n",
      "Elapsed time: 12 min, Current dataset size: 0.04 MB\n",
      "Elapsed time: 14 min, Current dataset size: 0.05 MB\n",
      "Elapsed time: 15 min, Current dataset size: 0.05 MB\n",
      "Elapsed time: 16 min, Current dataset size: 0.06 MB\n",
      "Elapsed time: 17 min, Current dataset size: 0.06 MB\n",
      "Elapsed time: 18 min, Current dataset size: 0.06 MB\n",
      "Elapsed time: 19 min, Current dataset size: 0.06 MB\n",
      "Elapsed time: 20 min, Current dataset size: 0.07 MB\n",
      "Elapsed time: 21 min, Current dataset size: 0.07 MB\n",
      "Elapsed time: 22 min, Current dataset size: 0.08 MB\n",
      "Elapsed time: 23 min, Current dataset size: 0.08 MB\n",
      "Elapsed time: 24 min, Current dataset size: 0.09 MB\n",
      "Elapsed time: 25 min, Current dataset size: 0.09 MB\n",
      "Elapsed time: 26 min, Current dataset size: 0.09 MB\n",
      "Elapsed time: 27 min, Current dataset size: 0.09 MB\n",
      "Elapsed time: 28 min, Current dataset size: 0.09 MB\n",
      "Elapsed time: 29 min, Current dataset size: 0.10 MB\n",
      "Elapsed time: 30 min, Current dataset size: 0.10 MB\n",
      "Elapsed time: 31 min, Current dataset size: 0.11 MB\n",
      "Elapsed time: 32 min, Current dataset size: 0.11 MB\n",
      "Elapsed time: 33 min, Current dataset size: 0.12 MB\n",
      "Elapsed time: 34 min, Current dataset size: 0.12 MB\n",
      "Elapsed time: 35 min, Current dataset size: 0.13 MB\n",
      "Elapsed time: 36 min, Current dataset size: 0.13 MB\n",
      "Elapsed time: 37 min, Current dataset size: 0.13 MB\n",
      "Elapsed time: 38 min, Current dataset size: 0.13 MB\n",
      "Elapsed time: 39 min, Current dataset size: 0.14 MB\n",
      "Elapsed time: 40 min, Current dataset size: 0.14 MB\n",
      "Elapsed time: 41 min, Current dataset size: 0.14 MB\n",
      "Elapsed time: 42 min, Current dataset size: 0.15 MB\n",
      "Elapsed time: 43 min, Current dataset size: 0.15 MB\n",
      "Elapsed time: 44 min, Current dataset size: 0.16 MB\n",
      "Elapsed time: 45 min, Current dataset size: 0.16 MB\n",
      "Elapsed time: 46 min, Current dataset size: 0.17 MB\n",
      "Elapsed time: 47 min, Current dataset size: 0.17 MB\n",
      "Elapsed time: 48 min, Current dataset size: 0.17 MB\n",
      "Elapsed time: 49 min, Current dataset size: 0.17 MB\n",
      "Elapsed time: 50 min, Current dataset size: 0.18 MB\n",
      "Elapsed time: 51 min, Current dataset size: 0.18 MB\n",
      "Elapsed time: 52 min, Current dataset size: 0.19 MB\n",
      "Elapsed time: 53 min, Current dataset size: 0.19 MB\n",
      "Elapsed time: 54 min, Current dataset size: 0.20 MB\n",
      "Elapsed time: 56 min, Current dataset size: 0.20 MB\n",
      "Elapsed time: 57 min, Current dataset size: 0.20 MB\n",
      "Elapsed time: 58 min, Current dataset size: 0.21 MB\n",
      "Elapsed time: 59 min, Current dataset size: 0.21 MB\n",
      "Elapsed time: 60 min, Current dataset size: 0.21 MB\n",
      "Elapsed time: 61 min, Current dataset size: 0.22 MB\n",
      "Elapsed time: 62 min, Current dataset size: 0.22 MB\n",
      "Elapsed time: 63 min, Current dataset size: 0.23 MB\n",
      "Elapsed time: 64 min, Current dataset size: 0.23 MB\n",
      "Elapsed time: 65 min, Current dataset size: 0.24 MB\n",
      "Elapsed time: 66 min, Current dataset size: 0.24 MB\n",
      "Elapsed time: 67 min, Current dataset size: 0.24 MB\n",
      "Elapsed time: 68 min, Current dataset size: 0.24 MB\n",
      "Elapsed time: 69 min, Current dataset size: 0.25 MB\n",
      "Elapsed time: 70 min, Current dataset size: 0.25 MB\n",
      "Elapsed time: 71 min, Current dataset size: 0.26 MB\n",
      "Elapsed time: 72 min, Current dataset size: 0.26 MB\n",
      "Elapsed time: 73 min, Current dataset size: 0.27 MB\n",
      "Elapsed time: 74 min, Current dataset size: 0.27 MB\n",
      "Elapsed time: 75 min, Current dataset size: 0.28 MB\n",
      "Elapsed time: 76 min, Current dataset size: 0.28 MB\n",
      "Elapsed time: 77 min, Current dataset size: 0.28 MB\n",
      "Elapsed time: 78 min, Current dataset size: 0.28 MB\n",
      "Elapsed time: 79 min, Current dataset size: 0.29 MB\n",
      "Elapsed time: 80 min, Current dataset size: 0.29 MB\n",
      "Elapsed time: 81 min, Current dataset size: 0.29 MB\n",
      "Elapsed time: 82 min, Current dataset size: 0.30 MB\n",
      "Elapsed time: 83 min, Current dataset size: 0.30 MB\n",
      "Elapsed time: 84 min, Current dataset size: 0.31 MB\n",
      "Elapsed time: 85 min, Current dataset size: 0.31 MB\n",
      "Elapsed time: 86 min, Current dataset size: 0.31 MB\n",
      "Elapsed time: 87 min, Current dataset size: 0.31 MB\n",
      "Elapsed time: 191 min, Current dataset size: 0.32 MB\n",
      "Elapsed time: 192 min, Current dataset size: 0.32 MB\n",
      "Elapsed time: 193 min, Current dataset size: 0.33 MB\n",
      "Elapsed time: 194 min, Current dataset size: 0.33 MB\n",
      "Elapsed time: 195 min, Current dataset size: 0.34 MB\n",
      "Elapsed time: 196 min, Current dataset size: 0.34 MB\n",
      "Elapsed time: 197 min, Current dataset size: 0.34 MB\n",
      "Elapsed time: 198 min, Current dataset size: 0.35 MB\n",
      "Elapsed time: 199 min, Current dataset size: 0.35 MB\n",
      "Elapsed time: 200 min, Current dataset size: 0.35 MB\n",
      "Elapsed time: 201 min, Current dataset size: 0.35 MB\n",
      "Elapsed time: 202 min, Current dataset size: 0.36 MB\n",
      "Elapsed time: 203 min, Current dataset size: 0.36 MB\n",
      "Elapsed time: 204 min, Current dataset size: 0.37 MB\n",
      "Elapsed time: 205 min, Current dataset size: 0.37 MB\n",
      "Elapsed time: 206 min, Current dataset size: 0.38 MB\n",
      "Elapsed time: 207 min, Current dataset size: 0.38 MB\n",
      "Elapsed time: 208 min, Current dataset size: 0.38 MB\n",
      "Elapsed time: 209 min, Current dataset size: 0.38 MB\n",
      "Elapsed time: 210 min, Current dataset size: 0.39 MB\n",
      "Elapsed time: 211 min, Current dataset size: 0.39 MB\n",
      "Elapsed time: 212 min, Current dataset size: 0.40 MB\n",
      "Elapsed time: 213 min, Current dataset size: 0.40 MB\n",
      "Elapsed time: 214 min, Current dataset size: 0.41 MB\n",
      "Elapsed time: 215 min, Current dataset size: 0.41 MB\n",
      "Elapsed time: 216 min, Current dataset size: 0.41 MB\n",
      "Elapsed time: 217 min, Current dataset size: 0.42 MB\n",
      "Elapsed time: 218 min, Current dataset size: 0.42 MB\n",
      "Elapsed time: 219 min, Current dataset size: 0.42 MB\n",
      "Elapsed time: 220 min, Current dataset size: 0.42 MB\n",
      "Elapsed time: 221 min, Current dataset size: 0.43 MB\n",
      "Elapsed time: 223 min, Current dataset size: 0.44 MB\n",
      "Elapsed time: 224 min, Current dataset size: 0.44 MB\n",
      "Elapsed time: 225 min, Current dataset size: 0.45 MB\n",
      "Elapsed time: 226 min, Current dataset size: 0.45 MB\n",
      "Elapsed time: 227 min, Current dataset size: 0.46 MB\n",
      "Elapsed time: 228 min, Current dataset size: 0.46 MB\n",
      "Elapsed time: 229 min, Current dataset size: 0.46 MB\n",
      "Elapsed time: 230 min, Current dataset size: 0.46 MB\n",
      "Elapsed time: 231 min, Current dataset size: 0.47 MB\n",
      "Elapsed time: 232 min, Current dataset size: 0.47 MB\n",
      "Elapsed time: 233 min, Current dataset size: 0.48 MB\n",
      "Elapsed time: 234 min, Current dataset size: 0.48 MB\n",
      "Elapsed time: 235 min, Current dataset size: 0.49 MB\n",
      "Elapsed time: 236 min, Current dataset size: 0.49 MB\n",
      "Elapsed time: 237 min, Current dataset size: 0.49 MB\n",
      "Elapsed time: 238 min, Current dataset size: 0.49 MB\n",
      "Elapsed time: 239 min, Current dataset size: 0.49 MB\n",
      "Elapsed time: 240 min, Current dataset size: 0.50 MB\n",
      "Elapsed time: 241 min, Current dataset size: 0.50 MB\n",
      "Elapsed time: 242 min, Current dataset size: 0.51 MB\n",
      "Elapsed time: 243 min, Current dataset size: 0.51 MB\n",
      "Elapsed time: 244 min, Current dataset size: 0.52 MB\n",
      "Elapsed time: 245 min, Current dataset size: 0.52 MB\n",
      "Elapsed time: 246 min, Current dataset size: 0.53 MB\n",
      "Elapsed time: 247 min, Current dataset size: 0.53 MB\n",
      "Elapsed time: 248 min, Current dataset size: 0.53 MB\n",
      "Elapsed time: 249 min, Current dataset size: 0.53 MB\n",
      "Elapsed time: 250 min, Current dataset size: 0.54 MB\n",
      "Elapsed time: 251 min, Current dataset size: 0.54 MB\n",
      "Elapsed time: 252 min, Current dataset size: 0.55 MB\n",
      "Elapsed time: 253 min, Current dataset size: 0.55 MB\n",
      "Elapsed time: 254 min, Current dataset size: 0.56 MB\n",
      "Elapsed time: 255 min, Current dataset size: 0.56 MB\n",
      "Elapsed time: 256 min, Current dataset size: 0.56 MB\n",
      "Elapsed time: 257 min, Current dataset size: 0.57 MB\n",
      "Elapsed time: 258 min, Current dataset size: 0.57 MB\n",
      "Elapsed time: 259 min, Current dataset size: 0.57 MB\n",
      "Elapsed time: 260 min, Current dataset size: 0.57 MB\n",
      "Elapsed time: 261 min, Current dataset size: 0.58 MB\n",
      "Elapsed time: 263 min, Current dataset size: 0.59 MB\n",
      "Elapsed time: 264 min, Current dataset size: 0.59 MB\n",
      "Elapsed time: 265 min, Current dataset size: 0.60 MB\n",
      "Elapsed time: 266 min, Current dataset size: 0.60 MB\n",
      "Elapsed time: 267 min, Current dataset size: 0.60 MB\n",
      "Elapsed time: 268 min, Current dataset size: 0.60 MB\n",
      "Elapsed time: 299 min, Current dataset size: 0.61 MB\n",
      "Elapsed time: 300 min, Current dataset size: 0.61 MB\n",
      "Data collection completed or interrupted.\n"
     ]
    }
   ],
   "source": [
    "import signal\n",
    "\n",
    "\n",
    "stop_collecting = False\n",
    "\n",
    "def handle_interrupt(signal, frame):\n",
    "    global stop_collecting\n",
    "    stop_collecting = True\n",
    "    print(\"\\nData collection interrupted by user.\")\n",
    "\n",
    "\n",
    "signal.signal(signal.SIGINT, handle_interrupt)\n",
    "\n",
    "# Start data collection\n",
    "start_time = time.time()\n",
    "end_time = start_time + duration_minutes * 60  # Duration in seconds\n",
    "\n",
    "print(\"Data collection started... (Press Ctrl+C to stop)\")\n",
    "\n",
    "with open(output_file, \"a\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    \n",
    "    while time.time() < end_time and not stop_collecting:\n",
    "        metrics = fetch_metrics()  \n",
    "        writer.writerow(metrics)  \n",
    "        \n",
    "        time.sleep(1 / sampling_rate_hz)\n",
    "        \n",
    "        #Print progress every minute\n",
    "        elapsed_seconds = int(time.time() - start_time)\n",
    "        if elapsed_seconds % 60 == 0:\n",
    "            current_size = os.path.getsize(output_file) / (1024 ** 2)  # File size in MB\n",
    "            print(f\"Elapsed time: {elapsed_seconds // 60} min, Current dataset size: {current_size:.2f} MB\")\n",
    "\n",
    "print(\"Data collection completed or interrupted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset size: 0.00 GB\n",
      "Final dataset size: 1.00 GB\n"
     ]
    }
   ],
   "source": [
    "# Load the existing dataset\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "# Check current file size\n",
    "current_size = os.path.getsize(output_file) / (1024 ** 3)  \n",
    "print(f\"Initial dataset size: {current_size:.2f} GB\")\n",
    "\n",
    "#Rows until file size reaches ~1 GB\n",
    "while os.path.getsize(output_file) < (1 * 1024 ** 3): \n",
    "    df.to_csv(output_file, mode=\"a\", index=False, header=False)\n",
    "\n",
    "final_size = os.path.getsize(output_file) / (1024 ** 3)\n",
    "print(f\"Final dataset size: {final_size:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset size: 1.00 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_size = os.path.getsize(output_file) / (1024 ** 3) \n",
    "print(f\"Final dataset size: {file_size:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    timestamp  cpu_temperature  cpu_usage  cpu_load  \\\n",
      "0  2024-11-29 00:39:00.063474              NaN       18.1       NaN   \n",
      "1  2024-11-29 00:39:01.144384              NaN       37.9       NaN   \n",
      "2  2024-11-29 00:39:02.229738              NaN       37.2       NaN   \n",
      "3  2024-11-29 00:39:03.256356              NaN       21.6       NaN   \n",
      "4  2024-11-29 00:39:04.289264              NaN       22.7       NaN   \n",
      "\n",
      "   memory_usage  battery_level  disk_usage  bytes_sent  bytes_recv  \n",
      "0          81.2             99        60.7     2168627    84916184  \n",
      "1          81.4             99        60.7     2168627    84916238  \n",
      "2          81.1             99        60.7     2173181    84916294  \n",
      "3          81.1             99        60.7     2173289    84916733  \n",
      "4          81.0             99        60.7     2173505    84916988  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(output_file, nrows=10) \n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    timestamp  cpu_temperature  cpu_usage  cpu_load  \\\n",
      "0  2024-11-27 22:38:17.267005              NaN       54.0       NaN   \n",
      "1  2024-11-27 22:38:18.323268              NaN       56.6       NaN   \n",
      "2  2024-11-27 22:38:19.331899              NaN       54.9       NaN   \n",
      "3  2024-11-27 22:38:20.340946              NaN       32.9       NaN   \n",
      "4  2024-11-27 22:38:21.350088              NaN       21.0       NaN   \n",
      "\n",
      "   memory_usage  battery_level  disk_usage  bytes_sent  bytes_recv  \n",
      "0          79.6             60         NaN     5582733    77757042  \n",
      "1          79.9             60         NaN     5594898    77762338  \n",
      "2          79.8             60         NaN     5595061    77762773  \n",
      "3          79.9             60         NaN     5595061    77762773  \n",
      "4          79.8             60         NaN     5603869    77763088  \n"
     ]
    }
   ],
   "source": [
    "# Define the correct column names\n",
    "correct_columns = [\n",
    "    \"timestamp\", \"cpu_temperature\", \"cpu_usage\", \"cpu_load\",\n",
    "    \"memory_usage\", \"battery_level\", \"disk_usage\", \"bytes_sent\", \"bytes_recv\"\n",
    "]\n",
    "\n",
    "# Assign the correct column names to the DataFrame\n",
    "df.columns = correct_columns\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    timestamp  cpu_temperature  cpu_usage  cpu_load  \\\n",
      "0  2024-11-29 00:39:00.063474              NaN       18.1       NaN   \n",
      "1  2024-11-29 00:39:01.144384              NaN       37.9       NaN   \n",
      "2  2024-11-29 00:39:02.229738              NaN       37.2       NaN   \n",
      "3  2024-11-29 00:39:03.256356              NaN       21.6       NaN   \n",
      "4  2024-11-29 00:39:04.289264              NaN       22.7       NaN   \n",
      "\n",
      "   memory_usage  battery_level  disk_usage  bytes_sent  bytes_recv  \n",
      "0          81.2             99        60.7     2168627    84916184  \n",
      "1          81.4             99        60.7     2168627    84916238  \n",
      "2          81.1             99        60.7     2173181    84916294  \n",
      "3          81.1             99        60.7     2173289    84916733  \n",
      "4          81.0             99        60.7     2173505    84916988  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   timestamp        10 non-null     object \n",
      " 1   cpu_temperature  0 non-null      float64\n",
      " 2   cpu_usage        10 non-null     float64\n",
      " 3   cpu_load         0 non-null      float64\n",
      " 4   memory_usage     10 non-null     float64\n",
      " 5   battery_level    10 non-null     int64  \n",
      " 6   disk_usage       10 non-null     float64\n",
      " 7   bytes_sent       10 non-null     int64  \n",
      " 8   bytes_recv       10 non-null     int64  \n",
      "dtypes: float64(5), int64(3), object(1)\n",
      "memory usage: 852.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.head())  \n",
    "print(df.info())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cpu_temperature  cpu_usage  cpu_load  memory_usage  battery_level  \\\n",
      "count             10.0  10.000000      10.0     10.000000           10.0   \n",
      "mean               0.0  21.890000       0.0     80.990000           99.0   \n",
      "std                0.0   8.677743       0.0      0.213177            0.0   \n",
      "min                0.0  14.800000       0.0     80.700000           99.0   \n",
      "25%                0.0  15.750000       0.0     80.825000           99.0   \n",
      "50%                0.0  18.400000       0.0     80.950000           99.0   \n",
      "75%                0.0  22.425000       0.0     81.100000           99.0   \n",
      "max                0.0  37.900000       0.0     81.400000           99.0   \n",
      "\n",
      "       disk_usage    bytes_sent    bytes_recv  \n",
      "count        10.0  1.000000e+01  1.000000e+01  \n",
      "mean         60.7  2.172508e+06  8.491686e+07  \n",
      "std           0.0  2.049950e+03  4.602376e+02  \n",
      "min          60.7  2.168627e+06  8.491618e+07  \n",
      "25%          60.7  2.173208e+06  8.491640e+07  \n",
      "50%          60.7  2.173532e+06  8.491709e+07  \n",
      "75%          60.7  2.173559e+06  8.491723e+07  \n",
      "max          60.7  2.173613e+06  8.491730e+07  \n"
     ]
    }
   ],
   "source": [
    "# Replace NaNs with a meaningful value or drop them\n",
    "df = df.fillna(0)  # Replace NaNs with 0\n",
    "df = df.dropna()  # Drop rows with NaN values\n",
    "\n",
    "# Verify after cleaning\n",
    "print(df.describe()) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
